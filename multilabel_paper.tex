% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{makecell}
\usepackage{url}
\usepackage{cite}
\usepackage{subfig}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
 % Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}
\setlength{\textfloatsep}{0.5cm}
%\addtolength{\parskip}{-0.3mm}

\begin{document}
%
\title{Combining Metric Learning and Graph Attention For Accurate and Efficient Multilabel Image Classification}
%
\titlerunning{}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Kirill Prokofiev\orcidID{0000-0001-9619-0248}\inst{1} \and \\
Vladislav Sovrasov\orcidID{0000-0001-6525-2602}\inst{2}}
%
\authorrunning{K. Prokofiev et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Intel, Higher School of Economics \email{kirill.prokofiev@intel.com}, \and
Intel, Nizhny Novgorod State University \email{vladislav.sovrasov@intel.com}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
  Multi-label image classification allows predicting a set of labels
  from a given image. Unlike multiclass classification, where
  only one label per image is assigned, such setup is applicable for a broader
  range of applications.
  In this work we propose an improvement for
  Graph Convolutional multilabel classification head, replacing it with
  Graph Attention head. Also, instead of Asymmetric Loss (ASL), which is de-facto
  a standard for multilabel classification, we propose to apply SphereFace2 binary loss
  for each of the underlying binary classification problems. SphereFace2 implicitly
  learns a proxy for each class and operates in angular space, providing a better
  discrimination ability, than binary cross entropy loss does on unnormalized features.
  We show that applying Graph Attention head and SphereFace2 outperform methods based on
  pure ASL, while performing on par with the latest transformer-based approaches
  on widespread multilabel classification benchmarks such as MS-COCO, PASCAL-VOC, NUS-Wide and Visual Genome 500.
  Source code of our method is available as a part of the OpenVINO{\texttrademark} Training
  Extensions\footnote{\url{https://github.com/openvinotoolkit/training_extensions}}.

\keywords{Multilabel image classification \and deep learning \and lightweight models \and graph attention}
\end{abstract}
%
%
%
\section{Introduction}

Starting from the impressive AlexNet \cite{alexnet} breakthrough on the ImageNet benchmark \cite{imagenet_cvpr09},
deep-learning era has drastically changed approaches to almost every computer vision task.
Throughout this process multiclass classification problem was a polygon for developing new
architectures \cite{He2016DeepRL, Howard2019SearchingFM, Tan2019EfficientNetRM} and learning paradigms \cite{chen2020simple, NEURIPS2020_d89a66c7, he2019moco}.
At the same time, multilabel classification has been developing not so intensively, although presence of several
labels on one image is more natural, than having one hard label. Due to lack of specialized multilabel datasets, researchers
turned general object detection datasets such as MS-COCO \cite{Lin2014MicrosoftCC} and PASCAL VOC \cite{Everingham2014ThePV} into
challenging multilabel classification benchmarks by removing bounding boxes from the data annotation and
leveraging their class labels only.

Two key challenges of multilabel classification are positive-negative imbalance and
modeling the inter-label dependencies. We tackle the imbalance challenge by applying
the modified SphereFace2\cite{Wen2021SphereFace2BC} loss. By it's nature this loss performs hard sample
mining by normalizing features and scaling logits. Combining SphereFace2 with ASL\cite{Baruch2021AsymmetricLF} focal weighting
provides even stronger mechanism for mining hard positives and discarding easy negatives.

Implicit label co-occurrence modeling is also beneficial for multilabel
classification \cite{Liu2021Query2LabelAS,ridnik2021mldecoder,Chen2019MultiLabelIR}.
Baseline classification architectures consist of a backbone (CNN or transformer), global pooling layer
and linear layer with binary classification losses attached to each logit. This architecture
can be augmented by a set of binary classifiers generated by stacked GCNs, which process a graph
built over vector representations of labels \cite{Chen2019MultiLabelIR}. Applying graph attention layers could improve
co-occurrence modeling.

The main contributions of this paper are as follows:
\begin{itemize}
  \item We first applied SphereFace2\cite{Wen2021SphereFace2BC} loss to multilabel classification task and
  propose a modified version of this loss, which adds ASL\cite{Baruch2021AsymmetricLF} mechanism to it.
  \item We improved GCN\cite{Chen2019MultiLabelIR} multilabel classification approach by incorporating graph attention layers.
  \item We studied the importance of per class confidence thresholds tuning for adapting models to real-world applications.
  \item We verify the effectiveness of our method with comprehensive experiments
  on widespread multilabel classification benchmarks: PASCAL VOC, MS-COCO, Visual Genome \cite{Krishna2016VisualGC}
  and NUS-WIDE \cite{Chua2009NUSWIDEAR}.
\end{itemize}


\section{Related Work}
Historically multilabel classification was attracting less attention than the multiclass scenario,
but nonetheless there is stills a great progress on that field. Notable progress was achieved by
developing advanced loss functions \cite{Baruch2021AsymmetricLF}, label co-occurrence modeling \cite{Chen2019MultiLabelIR, Yuan2022GraphAT},
designing advanced classification heads \cite{Liu2021Query2LabelAS, ridnik2021mldecoder, resAttn} and discovering
architectures taking into account spatial distribution of objects via exploring attentional regions
\cite{Wang2017MultilabelIR, Gao2021LearningTD}.

Each one-class classification subtask in multilabel scenario suffers from hard positives-negatives imbalance.
More classes the training dataset contains, more negatives we have for in each of the one-class subtasks, because
a single image typically contain a tiny fraction of the vast number of all classes. A modified asymmetric loss \cite{Baruch2021AsymmetricLF},
that down-weights and hard-thresholds easy negative samples, showed impressive results, reaching state-of-the-art results on multiple popular
multi-label datasets without any sophisticated architecture tricks. These results indicate that a proper choice of a loss
function is crucial for multilabel classification performance.

Another promising direction is designing class-specific classifiers instead of using a fully connected
layer on top of a single feature vector produced by a backbone network. This approach
also doesn't introduce additional training steps and marginally increases model complexity.
Authors of \cite{resAttn} propose a drop-in replacement of global average pooling layer that
generates class-specific features for every category. Leveraging compact transformer heads for
generating such features \cite{Liu2021Query2LabelAS, ridnik2021mldecoder} turned out to be even more
effective. This approach assumes pooling class-specific features by employing learnable embedding queries.

Taking into account spatial distribution of objects or label relationships based on prior knowledge requires
data pre-processing and additional assumptions \cite{Chen2019MultiLabelIR, Yuan2022GraphAT} or
sophisticated model architecture \cite{Wang2017MultilabelIR, Gao2021LearningTD}.
For instance, \cite{Chen2019MultiLabelIR} represents labels by word embeddings, then a directed graph is built over these label
representations, where each node denotes a label. Then stacked GCNs are learned over this graph to obtains a
set of object classifiers. This method relies on an ability to represent labels as words, which is not always possible.
Spacial distribution modeling requires having a RCNN-like \cite{Girshick2014RichFH}
module inside the model \cite{Wang2017MultilabelIR, Gao2021LearningTD}, which drastically increase
complexity of the training pipeline.


\section{Method}

\subsection{Model Architecture}

\subsection{Graph Attention Multilabel Head}

\subsection{Angular Margin Binary Classification}

\subsection{Details of Training Strategy}

\section{Experiments}

\begin{table}
  \caption{Comparison with the state-of-the-art on MS-COCO dataset.}
  \label{tab:results_coco}
  \centering
  \begin{tabular}{l|c|c|c}
    Method & Backbone & Input resolution & mAP \\ \hline
    ML-Decoder & TResNet-L & 448x448 & 90.0 \\
    \hline
    ML-Decoder + AMBinary (ours) & EfficientNet-V2-M & 448x448 & \\
  \end{tabular}
\end{table}


\begin{table}
  \caption{Comparison with the state-of-the-art on Pascal-VOC dataset.}
  \label{tab:results_voc}
  \centering
  \begin{tabular}{l|c|c|c}
    Method & Backbone & Input resolution & mAP \\ \hline
    ML-Decoder & TResNet-L & 448x448 &  \\
    \hline
    ML-Decoder + AMBinary (ours) & EfficientNet-V2-M & 448x448 & \\
  \end{tabular}
\end{table}


\begin{table}
  \caption{Comparison with the state-of-the-art on NUS-WIDE and VG500.}
  \label{tab:results_others}
  \centering
  \begin{tabular}{l|c|c}
    Method & NUS-WIDE & VG500\\ \hline
    TResNet-L, ML-Decoder &  & \\
    \hline
    EfficientNet-V2-M, ML-Decoder + AMBinary (ours) &  &  \\
  \end{tabular}
\end{table}

\subsection{Ablation Study}

\section{Conclusion}

%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{refs}
% \input{supplementary.tex}
\end{document}
